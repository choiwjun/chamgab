name: Weekly ML Training

on:
  schedule:
    # 매주 일요일 한국시간 03:00 (UTC 토요일 18:00)
    - cron: '0 18 * * 6'
  workflow_dispatch: # 수동 실행 가능
    inputs:
      force_retrain:
        description: '강제 재학습 여부'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.11'

jobs:
  check-data:
    name: 학습 데이터 확인
    runs-on: ubuntu-latest
    outputs:
      should_train: ${{ steps.check.outputs.should_train }}
      data_count: ${{ steps.check.outputs.data_count }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: ml-api/requirements.txt

      - name: Install dependencies
        run: |
          cd ml-api
          pip install -r requirements.txt

      - name: Check training data
        id: check
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python -c "
          import os
          from supabase import create_client

          supabase = create_client(
              os.environ['SUPABASE_URL'],
              os.environ['SUPABASE_SERVICE_KEY']
          )

          # 최근 일주일 새로운 거래 데이터 확인
          result = supabase.table('transactions').select('id', count='exact').execute()
          count = result.count or 0

          # 1000건 이상 새 데이터가 있으면 재학습
          should_train = 'true' if count >= 1000 or '${{ inputs.force_retrain }}' == 'true' else 'false'

          import subprocess
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f'should_train={should_train}\n')
              f.write(f'data_count={count}\n')
          print(f'Data count: {count}, Should train: {should_train}')
          "

  train-model:
    name: ML 모델 학습
    needs: check-data
    if: needs.check-data.outputs.should_train == 'true'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: ml-api/requirements.txt

      - name: Install dependencies
        run: |
          cd ml-api
          pip install -r requirements.txt

      - name: Prepare training data
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python scripts/prepare_training_data.py

      - name: Train XGBoost model
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python -m scripts.train_model

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ml-models-${{ github.run_number }}
          path: |
            ml-api/app/models/*.pkl
          retention-days: 30

      - name: Update model in Supabase Storage
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python -c "
          import os
          from supabase import create_client

          supabase = create_client(
              os.environ['SUPABASE_URL'],
              os.environ['SUPABASE_SERVICE_KEY']
          )

          # 모델 파일 업로드
          for name in ['xgboost_model.pkl', 'shap_explainer.pkl', 'feature_artifacts.pkl']:
              path = f'app/models/{name}'
              if os.path.exists(path):
                  with open(path, 'rb') as f:
                      supabase.storage.from_('ml-models').upload(
                          name,
                          f,
                          {'upsert': 'true'}
                      )
                  print(f'Uploaded {name}')

          print('Model uploaded to Supabase Storage')
          "

  evaluate-model:
    name: 모델 성능 평가
    needs: train-model
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: ml-models-${{ github.run_number }}
          path: ml-api/app/models/

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: ml-api/requirements.txt

      - name: Install dependencies
        run: |
          cd ml-api
          pip install -r requirements.txt

      - name: Evaluate model
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python -c "
          import pickle
          from pathlib import Path

          model_path = Path('app/models/xgboost_model.pkl')
          if not model_path.exists():
              print('모델 파일이 없습니다')
              exit(1)

          with open(model_path, 'rb') as f:
              model = pickle.load(f)

          print(f'모델 로드 성공: {type(model).__name__}')
          print(f'피처 수: {model.n_features_in_}')

          # 잔차 정보 확인
          residual_path = Path('app/models/residual_info.pkl')
          if residual_path.exists():
              with open(residual_path, 'rb') as f:
                  info = pickle.load(f)
              print(f'MAPE: {info.get(\"mape\", \"N/A\")}%')
              print(f'Test count: {info.get(\"test_count\", \"N/A\")}')
          else:
              print('잔차 정보 없음')

          print('모델 검증 완료')
          "

  notify-completion:
    name: 완료 알림
    needs: [check-data, train-model, evaluate-model]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Summary
        run: |
          echo "## ML Training Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Data check: ${{ needs.check-data.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Data count: ${{ needs.check-data.outputs.data_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- Training: ${{ needs.train-model.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Evaluation: ${{ needs.evaluate-model.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Completed at: $(date)" >> $GITHUB_STEP_SUMMARY
