name: Weekly ML Training

on:
  schedule:
    # 매주 일요일 한국시간 03:00 (UTC 토요일 18:00)
    - cron: '0 18 * * 6'
  workflow_dispatch: # 수동 실행 가능
    inputs:
      force_retrain:
        description: '강제 재학습 여부'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.11'

jobs:
  check-data:
    name: 학습 데이터 확인
    runs-on: ubuntu-latest
    outputs:
      should_train: ${{ steps.check.outputs.should_train }}
      data_count: ${{ steps.check.outputs.data_count }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: ml-api/requirements.txt

      - name: Install dependencies
        run: |
          cd ml-api
          pip install -r requirements.txt

      - name: Check training data
        id: check
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python -c "
          import os
          from supabase import create_client

          supabase = create_client(
              os.environ['SUPABASE_URL'],
              os.environ['SUPABASE_SERVICE_KEY']
          )

          # 최근 일주일 새로운 거래 데이터 확인
          result = supabase.table('transactions').select('id', count='exact').execute()
          count = result.count or 0

          # 1000건 이상 새 데이터가 있으면 재학습
          should_train = 'true' if count >= 1000 or '${{ inputs.force_retrain }}' == 'true' else 'false'

          print(f'::set-output name=should_train::{should_train}')
          print(f'::set-output name=data_count::{count}')
          print(f'Data count: {count}, Should train: {should_train}')
          "

  train-model:
    name: ML 모델 학습
    needs: check-data
    if: needs.check-data.outputs.should_train == 'true'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: ml-api/requirements.txt

      - name: Install dependencies
        run: |
          cd ml-api
          pip install -r requirements.txt

      - name: Prepare training data
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python scripts/prepare_training_data.py

      - name: Train XGBoost model
        run: |
          cd ml-api
          python scripts/train_model.py \
            --data-path data/training_data.parquet \
            --output-path models/ \
            --model-name price_predictor

      - name: Generate SHAP analysis
        run: |
          cd ml-api
          python scripts/generate_shap.py \
            --model-path models/price_predictor.joblib \
            --output-path models/shap_values.joblib

      - name: Upload model artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ml-models-${{ github.run_number }}
          path: |
            ml-api/models/*.joblib
            ml-api/models/*.json
          retention-days: 30

      - name: Update model in Supabase Storage
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python -c "
          import os
          from supabase import create_client

          supabase = create_client(
              os.environ['SUPABASE_URL'],
              os.environ['SUPABASE_SERVICE_KEY']
          )

          # 모델 파일 업로드
          with open('models/price_predictor.joblib', 'rb') as f:
              supabase.storage.from_('ml-models').upload(
                  'price_predictor_latest.joblib',
                  f,
                  {'upsert': 'true'}
              )

          print('Model uploaded to Supabase Storage')
          "

  evaluate-model:
    name: 모델 성능 평가
    needs: train-model
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Download model artifacts
        uses: actions/download-artifact@v4
        with:
          name: ml-models-${{ github.run_number }}
          path: ml-api/models/

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: ml-api/requirements.txt

      - name: Install dependencies
        run: |
          cd ml-api
          pip install -r requirements.txt

      - name: Evaluate model
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd ml-api
          python scripts/evaluate_model.py \
            --model-path models/price_predictor.joblib \
            --output-path reports/evaluation_${{ github.run_number }}.json

      - name: Upload evaluation report
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-report-${{ github.run_number }}
          path: ml-api/reports/
          retention-days: 90

  notify-completion:
    name: 완료 알림
    needs: [check-data, train-model, evaluate-model]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Summary
        run: |
          echo "## ML Training Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- Data check: ${{ needs.check-data.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Data count: ${{ needs.check-data.outputs.data_count }}" >> $GITHUB_STEP_SUMMARY
          echo "- Training: ${{ needs.train-model.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Evaluation: ${{ needs.evaluate-model.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Completed at: $(date)" >> $GITHUB_STEP_SUMMARY
